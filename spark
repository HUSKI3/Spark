#!/usr/bin/python3

import os
import glob
import sys
import tarfile
import subprocess
import platform

#print("Starting spark")
def main(*argv): 
    # Create directories for spark
    os.system("sudo mkdir -p /usr/.spark")
    os.system("sudo mkdir -p /usr/.spark/tmp")
    os.system("sudo mkdir -p /usr/.spark/packs && sudo touch /usr/.spark/packs/installed && sudo chmod 777 /usr/.spark/packs/installed")
    os.system("sudo mkdir -p /usr/.spark/dimensions")
    cmd = list(argv[0])
    x = 0
    #print("Checking Dimensions")
    #print(glob.glob("dimensions/*.sources"))
    try:
      # check if it exists
      cmd[1] 
    except IndexError:
      print("[Spark] Please specify a function")
      quit()
    # If route install
    if cmd[1] == "install":
      while True:
        #print(x)
        #print(str(glob.glob("/usr/.spark/dimensions/*.sources")))
        # Get sources
        dimfile = str(glob.glob("/usr/.spark/dimensions/*.sources")[x])
        #print(dimfile)
        # Read sources files
        with open(dimfile,"r") as file:
          data = file.readlines()
          #print(data)
          if str(cmd[2]) in str(data):
            #print("Found source in dimension ",dimfile)
            dimension = dimfile.split("/", 1)[1]
            break
        x+=1
      # Show selected dimension
      if dimension == "usr/.spark/dimensions/omniverse.sources":
        debian = True
      else:
        debian = False
      f =open(dimfile,"r")
      link = f.readlines()
      for y in link:
        if str(cmd[2]) in y:
          downlink=y
      link = downlink.split()
      if str(link[2]) != "/":
        srcdir = str(link[2])
      else:
         srcdir = "." 
      #Get complexity 
      if str(link[2]) != "/":
        srcdir = str(link[2])
      else:
         srcdir = "." 
      with open("/usr/.spark/packs/installed", "r") as f:
        inst = f.readlines()
        if cmd[2]+"," in inst:
          print("Already installed!")
          quit()
      with open("/usr/.spark/packs/installed", "a") as f:
        inst = f.write(" "+cmd[2]+",")
      # Get the download link
      link = str(link[1]) 
      #print(link)
      #Show which package is to be installed
      print("Package:", cmd[2])
      print("Dimension: ",dimension)
      print("Preparing to install...",srcdir)
      while True:
        try:
          # If debian install as a deb package
          if debian:
            download_link = str('''wget -q'''+str(" -O ")+str(cmd[2]+str(".deb"))+''' --user-agent="Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36" '''+str(link))
          else:
            download_link = str('''wget -q'''+str(" -O ")+str(cmd[2]+str(".tar.gz"))+''' --user-agent="Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36" '''+str(link))
          #print(download_link)
          os.system("cd /usr/.spark/tmp && sudo "+str(download_link))
          break
        except:
          print("ERROR - could not download ",arg1)
          break
      #print(cmd[1]," has ",len(glob.glob(str(cmd[2])+"*")))
      # If debian install using dpkg
      if debian:
        print("Unpacking (debian "+dimension+")")
        # Do somethign here later
        print("Building (debian ",dimension,")")
      # If not debian install as generic
      else:
        print("Unpacking (generic "+dimension+")")
        os.system("cd /usr/.spark/tmp && sudo tar xzf "+str(cmd[2])+".tar.gz")
        #tf = tarfile.open("/usr/.spark/tmp/"+str(cmd[2])+".tar.gz")
        #tf.extractall("/usr/.spark/packs/") 
        print("Building (generic ",dimension,")")
      if "igniteverse.sources" in dimension:
        try:
          subprocess.run(['cd','/usr/.spark/tmp/',str(cmd[2]),'*','&&','export','FORCE_UNSAFE_CONFIGURE=1','&','sudo','bash','configure','--prefix=/usr','--sysconfdir=/etc','--enable-utf8'], check = True, shell=True)
        except:
          print ('No configure! Aborting!')  
        os.system("cd /usr/.spark/tmp/"+str(cmd[2])+"*/"+srcdir+" && sudo make && sudo make install && sudo install -v -m644 "+str(cmd[2]))
      elif "omniverse" in dimension:
        print(cmd[2])
        os.system("cd /usr/.spark/tmp/ &&" + '''sudo dpkg -i '''+str(cmd[2])+"*")
      elif "universe" in dimension:
        print(cmd[2])
        print("Checking for build instructions...")
        os.system("cd /usr/.spark/tmp/ &&" + ''' thing'''+str(cmd[2])+"*")
      else:
        print("Dimension has no build instructions!")
    elif cmd [1] == "update":
      os.system(str('''cd /usr/.spark/dimensions && sudo rm -r *'''))
      link = "-O igniteverse.sources https://raw.githubusercontent.com/HUSKI3/Spark-ready-Packages/master/dimensions/igniteverse.sources"
      os.system(str('''cd /usr/.spark/dimensions && sudo wget -q'''+''' --user-agent="Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36" '''+str(link)))
      link = "-O omniverse.sources https://raw.githubusercontent.com/HUSKI3/Spark-ready-Packages/master/dimensions/omniverse.sources"
      os.system(str('''cd /usr/.spark/dimensions && sudo wget -q'''+''' --user-agent="Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36" '''+str(link)))
      link = "-O multiverse.sources https://raw.githubusercontent.com/HUSKI3/Spark-ready-Packages/master/dimensions/multiverse.sources"
      os.system(str('''cd /usr/.spark/dimensions && sudo wget -q'''+''' --user-agent="Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36" '''+str(link)))
      print("Updated Dimensions")
      print("Run 'spark upgrade' to upgrade utilities and libraries")
    elif cmd[1] == "help":
      print('''Spark is a simple and easy to use package manager for linux, it is created on a system of pipes and universes to manage versions of packages and distributions it can download them on. \nspark install <package>\nspark update \nspark help \nspark installed \nspark system (WIP, but very pretty)''')
    elif cmd[1] == "clear":
      print("Cleaning tmp...")
      os.system(str('''cd /usr/.spark/tmp && sudo rm -r *'''))
      print("Cleaned!")
    elif cmd[1] == "system":
      with open("/proc/cpuinfo", "r")  as f:
        info = f.readlines()
      cpuinfo = [x.strip().split(":")[1] for x in info if "model name"  in x]
      with open("/proc/meminfo", "r") as f:
          lines = f.readlines()
      with open("/proc/loadavg", "r") as f:
        load = f.read().strip()
      print(str('''         _nnnn_
        dGGGGMMb
       @p~qp~~qMb            Arch:    '''+platform.architecture()[0]+'''
       M|@||@) M|            Machine: '''+platform.machine()+'''
       @,----.JM|            Node:    '''+platform.node()+'''
      JS^\__/  qKL           System:  '''+platform.system()+'''
     dZP        qKRb         CPU:     '''+str(cpuinfo[0])+'''
    dZP          qKKb        Memory: 
   fZP            SMMb          '''+str(lines[0].strip())+'''
   HZM            MMMM          '''+str(lines[1].strip())+'''
   FqM            MMMM       Load:    '''+str(load)+'''
 __| ".        |\dS"qML
 |    `.       | `' \Zq
_)      \.___.,|     .'
\____   )MMMMMP|   .'
     `-'       `--' '''))
    elif cmd[1] == "installed":
      with open("/usr/.spark/packs/installed", "r") as f:
        inst= f.readlines()
      for elem in inst:
        print(elem)
    else:
      print("No such function!")
if __name__ == "__main__":
   main(sys.argv)

